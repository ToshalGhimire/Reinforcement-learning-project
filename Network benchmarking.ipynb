{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Input, Lambda, multiply\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = Input(shape=(4, 80, 80), name='states')\n",
    "# actions = Input(shape=(3,), name='actions')\n",
    "\n",
    "# scaled = Lambda(lambda x:x/255)(states)\n",
    "\n",
    "# conv1 = Conv2D(16, (8, 8), activation='relu', padding='same')(scaled)\n",
    "# # pool1 = MaxPooling2D(pool_size=(4, 4), strides=(4, 4))(conv1)\n",
    "# conv2 = Conv2D(32, (4, 4), activation='relu', padding='same')(conv1)\n",
    "# # pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)\n",
    "\n",
    "# flattened = Flatten()(conv2)\n",
    "# dense = Dense(256, activation='relu')(flattened)\n",
    "# output = Dense(3)(dense)\n",
    "# filtered_output = multiply([output, actions])\n",
    "\n",
    "# model = Model(inputs=[states, actions], outputs=filtered_output)\n",
    "# model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards = get_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards = np.array(states).reshape((len(states), 80, 80, 1)), \\\n",
    "                           np.array(actions), \\\n",
    "                           np.array(rewards).reshape((len(rewards), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RingBuffer:\n",
    "    def __init__(self, capacity=50000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def append(self, datum):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(datum)\n",
    "        else: \n",
    "            self.memory[self.position] = datum\n",
    "            \n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, min(batch_size, len(self.memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = RingBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon():\n",
    "    i = 0\n",
    "    while(True):\n",
    "        yield (1-0.9*(i/1000000)) if i < 1000000 else 0.1\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = [2, 0, 5]\n",
    "MAX_GRAYSCALE = 255.0\n",
    "BATCH_SIZE = 32\n",
    "UP = 2\n",
    "NOOP = 0\n",
    "DOWN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (8, 8), input_shape=(80, 80, 4), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 80, 80, 16)        4112      \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 80, 80, 32)        8224      \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 204800)            0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               52429056  \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 52,442,163\n",
      "Trainable params: 52,442,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn(env, model, gamma=0.9, *args):\n",
    "    get_ep = get_epsilon()\n",
    "    done = False\n",
    "    memory = RingBuffer()\n",
    "    s_t = process_data(env.reset(), init=True)\n",
    "    loss = 0\n",
    "    \n",
    "    S_t = s_t.repeat(4, axis=3)\n",
    "    \n",
    "    for t in itertools.count():\n",
    "        if np.random.random() <= next(get_ep):\n",
    "            action_idx = np.random.randint(0, 3)\n",
    "        else:\n",
    "            action_idx = np.argmax(model.predict(state))\n",
    "            \n",
    "        s_t_prime, reward, done, info = env.step(ACTIONS[action_idx])\n",
    "        s_t_prime = process_data(s_t_prime, init=True)\n",
    "                \n",
    "        S_t_prime = np.append(s_t_prime, S_t[:,:,:,:3], axis=3)\n",
    "        \n",
    "        memory.append((S_t, action_idx, reward, S_t_prime, done))\n",
    "        \n",
    "        env.render()\n",
    "        \n",
    "        if t > 400:\n",
    "            batch = memory.sample(BATCH_SIZE)\n",
    "            \n",
    "            states_t, actions_t, rewards_t, states_t_prime, done_t = [], [], [], [], []\n",
    "            for state, action, reward, state_prime, done in batch:\n",
    "                states_t.append(state[0])\n",
    "                actions_t.append(action)\n",
    "                rewards_t.append(reward)\n",
    "                states_t_prime.append(state_prime[0])\n",
    "                done_t.append(done)\n",
    "                \n",
    "            states_t = np.array(states_t)\n",
    "            states_t_prime = np.array(states_t_prime)\n",
    "                \n",
    "            Q_sa_prime = model.predict(states_t)\n",
    "            Q_sa = model.predict(states_t_prime)\n",
    "            \n",
    "            Q_sa_prime[:, actions_t] = rewards_t + gamma*np.max(Q_sa, axis=1)*np.invert(done_t)\n",
    "            \n",
    "            loss += model.train_on_batch(states_t, Q_sa_prime)\n",
    "            print(loss)\n",
    "        \n",
    "        S_t = S_t_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.506897211074829\n",
      "4.699760675430298\n",
      "5.927212238311768\n",
      "7.36489725112915\n",
      "7.8603794276714325\n",
      "8.817308157682419\n",
      "9.280901163816452\n",
      "9.635805875062943\n",
      "9.8429656624794\n",
      "10.176226019859314\n",
      "10.346973285079002\n",
      "10.5488810390234\n",
      "11.114807114005089\n",
      "11.434024915099144\n",
      "11.508469045162201\n",
      "11.571938633918762\n",
      "11.685678631067276\n",
      "11.735869988799095\n",
      "11.832798905670643\n",
      "11.893268540501595\n",
      "11.954121999442577\n",
      "12.006131909787655\n",
      "12.052553858608007\n",
      "12.078924801200628\n",
      "12.113744542002678\n",
      "12.13564833253622\n",
      "12.154784049838781\n",
      "12.174413915723562\n",
      "12.184259906411171\n",
      "12.623053535819054\n",
      "12.849636435508728\n",
      "12.885903976857662\n",
      "12.894569186493754\n",
      "12.899832791648805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-355-8a877d8ed78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-353-d03f9e22759d>\u001b[0m in \u001b[0;36mq_learn\u001b[0;34m(env, model, gamma, *args)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mQ_sa_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_sa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_sa_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSCI-4622-Machine-Learning-18fa/keras_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSCI-4622-Machine-Learning-18fa/keras_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSCI-4622-Machine-Learning-18fa/keras_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSCI-4622-Machine-Learning-18fa/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "q_learn(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, init=False):\n",
    "    cropped = data[34:-16,:]\n",
    "    if init:\n",
    "        return (np.mean(cropped[::2,::2,:], axis=2)/255.0).reshape((1, 80, 80, 1))\n",
    "    else: \n",
    "        return (np.mean(cropped[::2,::2,:], axis=2)/255.0).reshape((80, 80, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(action):\n",
    "    if action == UP: return [1, 0, 0]\n",
    "    elif action == NOOP: return [0, 1, 0]\n",
    "    else: return [0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(ob).repeat(4, axis=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(model, memory, batch_size=32):\n",
    "    batch = memory.sample(batch_size)\n",
    "    \n",
    "    states = [_[0] for _ in batch]\n",
    "    s_primes = [_[3] for _ in batch]\n",
    "    \n",
    "    p = model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
